from bs4 import BeautifulSoup
import requests
import time
import pandas as pd
from datetime import datetime
import logging
from sqlalchemy import create_engine
import os
from dotenv import load_dotenv


logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def fetch_page(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        logger.info(f"Successfully fetched {url}")
        return response.text
    except requests.RequestException as e:
        logger.error(f"Error fetching {url}: {e}")
        return None

def parse_make_page(html, make_name):
    """
    Parses the HTML content of a car make page to extract model information and complaint counts.
    Args:
        html (str): The HTML content of the car make page.
        make_name (str): The name of the car make to exclude from the model list.
    Returns:
        list[dict]: A list of dictionaries, where each dictionary contains:
            - 'model' (str): The name of the car model.
            - 'complaint_count' (int): The number of complaints associated with the model.
    """
    soup = BeautifulSoup(html, 'html.parser')
    model_links = soup.select('ul.column.bar li a')
    models = []
    seen_urls = set()
    
    for link in model_links:
        url = f"https://www.carcomplaints.com{link['href']}"
        model_name = link.text.strip()
        count_span = link.find_next_sibling('span', class_='count')
        complaint_count = int(count_span.text.replace(',', '')) if count_span else 0
        
        if url not in seen_urls and model_name and model_name != make_name:
            models.append({
                'model': model_name,
                'complaint_count': complaint_count
            })
            seen_urls.add(url)
    
    return models

def fetch_all_makes_complaints():
    ''' makes = [
        'Acura', 'Chrysler', 'Hyundai', 'Mazda', 'Oldsmobile', 'Scion',
        'Audi', 'Dodge', 'Infiniti', 'Mercedes-Benz', 'Plymouth', 'Subaru',
        'BMW', 'Ford', 'Jeep', 'Mercury', 'Pontiac', 'Tesla',
        'Buick', 'Genesis', 'Kia', 'Mini', 'Porsche', 'Toyota',
        'Cadillac', 'GMC', 'Lexus', 'Mitsubishi', 'Ram', 'Volvo',
        'Chevrolet', 'Honda', 'Lincoln', 'Nissan', 'Rivian', 'VW'
    ]
    '''
        # Load environment variables
    load_dotenv()
    
    # PostgreSQL connection details
    pg_user = os.environ['PG_USER']
    pg_password = os.environ['PG_PASSWORD']
    pg_host = os.environ['PG_HOST']
    pg_db = os.environ['PG_DB']
    
    # Create PostgreSQL connection string and engine
    pg_conn_str = f'postgresql+psycopg2://{pg_user}:{pg_password}@{pg_host}/{pg_db}'
    pg_engine = create_engine(pg_conn_str)

    makes = [
         'Toyota'
    ]

    all_models_data = []
    
    for make_name in makes:
        logger.info(f"\nProcessing make: {make_name}")
        html = fetch_page(f'https://www.carcomplaints.com/{make_name}/')
        if html:
            models = parse_make_page(html, make_name)
            for model in models:
                all_models_data.append({
                    'Make': make_name,
                    'Model': model['model'],
                    'Complaint count': model['complaint_count'],
                    'extract_date': datetime.now().date()
                })
        else:
            logger.error(f"Failed to fetch data for {make_name}")
        time.sleep(2) 
    
    df = pd.DataFrame(all_models_data)
    
    # Write to PostgreSQL
    try:
        df.to_sql('car_complaints', pg_engine, schema='sql_project', 
                  if_exists='append', index=False)
        logger.info("Data successfully written to PostgreSQL database")
    except Exception as e:
        logger.error(f"Error writing to database: {e}")
        # Save to CSV as backup
        output_file = f'toyota_complaints_{datetime.now().strftime("%Y%m%d")}.csv'
        df.to_csv(output_file, index=False)
        logger.info(f"Backup data saved to {output_file}")
    
    return df



if __name__ == "__main__":
    df = fetch_all_makes_complaints()
    print(f"\nTotal records: {len(df):,}")
    logger.info("\nScript completed successfully!")
