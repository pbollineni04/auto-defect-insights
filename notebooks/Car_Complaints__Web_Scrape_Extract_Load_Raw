from bs4 import BeautifulSoup
import requests
import time
import pandas as pd
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def fetch_page(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        logger.info(f"Successfully fetched {url}")
        return response.text
    except requests.RequestException as e:
        logger.error(f"Error fetching {url}: {e}")
        return None

def parse_make_page(html, make_name):
    soup = BeautifulSoup(html, 'html.parser')
    model_links = soup.select('ul.column.bar li a')
    models = []
    seen_urls = set()
    
    for link in model_links:
        url = f"https://www.carcomplaints.com{link['href']}"
        model_name = link.text.strip()
        count_span = link.find_next_sibling('span', class_='count')
        complaint_count = int(count_span.text.replace(',', '')) if count_span else 0
        
        if url not in seen_urls and model_name and model_name != make_name:
            models.append({
                'model': model_name,
                'complaint_count': complaint_count
            })
            seen_urls.add(url)
    
    return models

def fetch_all_makes_complaints():
    makes = [
        'Acura', 'Chrysler', 'Hyundai', 'Mazda', 'Oldsmobile', 'Scion',
        'Audi', 'Dodge', 'Infiniti', 'Mercedes-Benz', 'Plymouth', 'Subaru',
        'BMW', 'Ford', 'Jeep', 'Mercury', 'Pontiac', 'Tesla',
        'Buick', 'Genesis', 'Kia', 'Mini', 'Porsche', 'Toyota',
        'Cadillac', 'GMC', 'Lexus', 'Mitsubishi', 'Ram', 'Volvo',
        'Chevrolet', 'Honda', 'Lincoln', 'Nissan', 'Rivian', 'VW'
    ]
    
    all_models_data = []
    
    for make_name in makes:
        logger.info(f"\nProcessing make: {make_name}")
        html = fetch_page(f'https://www.carcomplaints.com/{make_name}/')
        if html:
            models = parse_make_page(html, make_name)
            for model in models:
                all_models_data.append({
                    'Make': make_name,
                    'Model': model['model'],
                    'Complaint count': model['complaint_count']
                })
        else:
            logger.error(f"Failed to fetch data for {make_name}")
        time.sleep(2)  # Rate limiting
    
    df = pd.DataFrame(all_models_data)
    output_file = f'all_makes_complaints_{datetime.now().strftime("%Y%m%d")}.csv'
    df.to_csv(output_file, index=False)
    logger.info(f"\nData saved to {output_file}")
    
    return df

if __name__ == "__main__":
    df = fetch_all_makes_complaints()
    print(f"\nTotal records: {len(df):,}")
    logger.info("\nScript completed successfully!")
